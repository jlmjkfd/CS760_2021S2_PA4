{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import fileinput\n",
    "import random\n",
    "import scipy.special\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pickle\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_path = 'alltitles'\n",
    "timestamps_path = 'alltimes'\n",
    "stopwords_path = 'stopwords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "timestamps = []\n",
    "dictionary = set()\n",
    "stopwords = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in fileinput.input(stopwords_path):\n",
    "    stopwords.update(set(line.lower().strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileinput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in fileinput.input(documents_path):\n",
    "    words = [word for word in doc.lower().strip().split() if word not in stopwords]\n",
    "    documents.append(words)\n",
    "    dictionary.update(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileinput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for timestamp in fileinput.input(timestamps_path):\n",
    "    num_titles = int(timestamp.strip().split()[0])\n",
    "    timestamp = float(timestamp.strip().split()[1])\n",
    "    timestamps.extend([timestamp for title in range(num_titles)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_timestamp = timestamps[0]\n",
    "last_timestamp = timestamps[len(timestamps)-1]\n",
    "timestamps = [1.0*(t-first_timestamp)/(last_timestamp-first_timestamp) for t in timestamps]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = list(dictionary)\n",
    "assert len(documents) == len(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "par = {}   \n",
    "par['T'] = 10\n",
    "par['alpha'] = [50.0/par['T'] for _ in range(par['T'])]\n",
    "print(par['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par['psi'] = [[1 for _ in range(2)] for _ in range(par['T'])] # psi = distribution of words for each topic k        \n",
    "par['betafunc_psi'] = [scipy.special.beta( par['psi'][t][0], par['psi'][t][1] ) for t in range(par['T'])]\n",
    "par['betafunc_psi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = {}                        # dictionary of all parameters\n",
    "par['dataset'] = 'pnas'         # dataset name\n",
    "par['max_iterations'] = 100     # max number of iterations in gibbs sampling\n",
    "par['T'] = 10                   # number of topics\n",
    "par['D'] = len(documents)       # number of documents\n",
    "par['V'] = len(dictionary)      # number of unique words in dictionary\n",
    "par['N'] = [len(doc) for doc in documents]              # length of each document in documents\n",
    "par['alpha'] = [50.0/par['T'] for _ in range(par['T'])] # alpha = 50 / number of topics. len(par['alpha']) = num of topics\n",
    "par['beta'] = [0.1 for _ in range(par['V'])]            # beta = 0.1. len(par['beta']) = num of unique words in `dictionary`.\n",
    "par['beta_sum'] = sum(par['beta'])                      # this is for TopicsOverTimeGibbsSampling()\n",
    "par['psi'] = [[1 for _ in range(2)] for _ in range(par['T'])] # parameter of Beta distribution, this step is for initialisation\n",
    "par['betafunc_psi'] = [scipy.special.beta( par['psi'][t][0], par['psi'][t][1] ) for t in range(par['T'])] # Beta distribution of time specific to topic\n",
    "par['word_id'] = {dictionary[i]: i for i in range(len(dictionary))} # assign id for each word in dictionary\n",
    "par['word_token'] = dictionary # assign a set of unique words from `dictionary` to `word_token`\n",
    "par['z'] = [[random.randrange(0,par['T']) for _ in range(par['N'][d])] for d in range(par['D'])] # initialise - assign a random topic to each word in each document\n",
    "par['t'] = [[timestamps[d] for _ in range(par['N'][d])] for d in range(par['D'])] # initialise - assign a random timestamp to each word in each document\n",
    "par['w'] = [[par['word_id'][documents[d][i]] for i in range(par['N'][d])] for d in range(par['D'])] # assign the id of each unique word in `dictionary` to `w`\n",
    "par['m'] = [[0 for t in range(par['T'])] for d in range(par['D'])] # initialise theta: proportion of topics in each document)\n",
    "par['n'] = [[0 for v in range(par['V'])] for t in range(par['T'])] # initialise phi: word distribution for each topic\n",
    "par['n_sum'] = [0 for t in range(par['T'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(par['D']):              # for each document\n",
    "    for i in range(par['N'][d]):         # for each word in each document\n",
    "        topic_di = par['z'][d][i]          # topic in doc d at word i\n",
    "        word_di = par['w'][d][i]           # word ID in doc d at word i\n",
    "        par['m'][d][topic_di] += 1         # \n",
    "        par['n'][topic_di][word_di] += 1\n",
    "        par['n_sum'][topic_di] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GetTopicTimestamps(self, par):\n",
    "topic_timestamps = []\n",
    "for topic in range(par['T']): \n",
    "    current_topic_timestamps = [] \n",
    "    current_topic_doc_timestamps = [[ (par['z'][d][i]==topic)*par['t'][d][i] for i in range(par['N'][d])] for d in range(par['D'])]\n",
    "#     for d in range(par['D']):\n",
    "#         current_topic_doc_timestamps[d] = filter(lambda x: x!=0, current_topic_doc_timestamps[d])\n",
    "#     for timestamps in current_topic_doc_timestamps:\n",
    "#         current_topic_timestamps.extend(timestamps)\n",
    "#     assert current_topic_timestamps != []\n",
    "#     topic_timestamps.append(current_topic_timestamps)\n",
    "#     return topic_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0009411336106135584, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_topic_doc_timestamps[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0009411336106135584]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_topic_doc_timestamps[18] = filter(lambda x: x!=0, current_topic_doc_timestamps[18])\n",
    "list(current_topic_doc_timestamps[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_topic_timestamps.extend(current_topic_doc_timestamps[18])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
